{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# RESNET\n",
    "\n",
    "## The Wide ResNet Model\n",
    "\n",
    "\n",
    "We'll be using a Wide Residual Network to train on this dataset, which is a convolutional neural network proven to perform very well in image classification challenges. Feel free to take some time to learn more about wide residual networks, the original residual networks they are based on, or about convolutional neural networks in general.\n",
    "\n",
    "\n",
    "In the early days of CNNs, the community drove towards very deep models (many tens or hundreds of layers), but as computing power advanced and algorithms improved, in particular after the idea of the residual block was demonstrated, it became more desirable to swing back towards shallower networks with wider layers, which was the primary innovation of the WideResNet family of models. The WideResNet-16-10 we will use below can achieve with O(10 million) parameters accuracy that is competitive with much deeper networks with more parameters.\n"
   ],
   "id": "43c4fa04aee66229"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Standard convolution block followed by batch normalization ",
   "id": "1329c5c541cf474b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class cbrblock(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super(cbrblock, self).__init__()\n",
    "        self.cbr = nn.Sequential(nn.Conv2d(input_channels, output_channels, kernel_size=3, stride=(1,1),\n",
    "                                           padding='same', bias=False),\n",
    "                                 nn.BatchNorm2d(output_channels),\n",
    "                                 nn.ReLU()\n",
    "                                 )\n",
    "    def forward(self, x):\n",
    "        out = self.cbr(x)\n",
    "        return out"
   ],
   "id": "bd361efbc1dc5977"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Basic residual block",
   "id": "66d5a37fa4d03b3d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class conv_block(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, scale_input):\n",
    "        super(conv_block, self).__init__()\n",
    "        self.scale_input = scale_input\n",
    "        if self.scale_input:\n",
    "            self.scale = nn.Conv2d(input_channels, output_channels, kernel_size=1, stride=(1,1),\n",
    "                                   padding='same')\n",
    "        self.layer1 = cbrblock(input_channels, output_channels)\n",
    "        self.dropout = nn.Dropout(p=0.01)\n",
    "        self.layer2 = cbrblock(output_channels, output_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.layer1(x)\n",
    "        out = self.dropout(out)\n",
    "        out = self.layer2(out)\n",
    "        if self.scale_input:\n",
    "            residual = self.scale(residual)\n",
    "        out = out + residual\n",
    "\n",
    "        return out"
   ],
   "id": "927a95509bc5ce99"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model",
   "id": "46213805089ee8f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class WideResNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(WideResNet, self).__init__()\n",
    "        nChannels = [1, 16, 160, 320, 640]\n",
    "\n",
    "        self.input_block = cbrblock(nChannels[0], nChannels[1])\n",
    "\n",
    "        # Module with alternating components employing input scaling\n",
    "        self.block1 = conv_block(nChannels[1], nChannels[2], 1)\n",
    "        self.block2 = conv_block(nChannels[2], nChannels[2], 0)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.block3 = conv_block(nChannels[2], nChannels[3], 1)\n",
    "        self.block4 = conv_block(nChannels[3], nChannels[3], 0)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.block5 = conv_block(nChannels[3], nChannels[4], 1)\n",
    "        self.block6 = conv_block(nChannels[4], nChannels[4], 0)\n",
    "\n",
    "        # Global average pooling\n",
    "        self.pool = nn.AvgPool2d(7)\n",
    "\n",
    "        # Feature flattening followed by linear layer\n",
    "        self.flat = nn.Flatten()\n",
    "        self.fc = nn.Linear(nChannels[4], num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.input_block(x)\n",
    "        out = self.block1(out)\n",
    "        out = self.block2(out)\n",
    "        out = self.pool1(out)\n",
    "        out = self.block3(out)\n",
    "        out = self.block4(out)\n",
    "        out = self.pool2(out)\n",
    "        out = self.block5(out)\n",
    "        out = self.block6(out)\n",
    "        out = self.pool(out)\n",
    "        out = self.flat(out)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out"
   ],
   "id": "beb9105197925a99"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train(model, optimizer, train_loader, loss_fn, device):\n",
    "    model.train()\n",
    "    for images, labels in train_loader:\n",
    "        # Transfering images and labels to GPU if available\n",
    "        labels = labels.to(device)\n",
    "        images = images.to(device)\n",
    "\n",
    "        # Forward pass \n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        # Setting all parameter gradients to zero to avoid gradient accumulation\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating model parameters\n",
    "        optimizer.step()\n"
   ],
   "id": "31d3e5ee9b77f307"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def test(model, test_loader, loss_fn, device):\n",
    "    total_labels = 0\n",
    "    correct_labels = 0\n",
    "    loss_total = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            # Transfering images and labels to GPU if available\n",
    "            labels = labels.to(device)\n",
    "            images = images.to(device)\n",
    "\n",
    "            # Forward pass \n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            # Extracting predicted label, and computing validation loss and validation accuracy\n",
    "            predictions = torch.max(outputs, 1)[1]\n",
    "            total_labels += len(labels)\n",
    "            correct_labels += (predictions == labels).sum()\n",
    "            loss_total += loss\n",
    "\n",
    "    v_accuracy = correct_labels / total_labels\n",
    "    v_loss = loss_total / len(test_loader)\n",
    "\n",
    "    return v_accuracy, v_loss"
   ],
   "id": "349d2faf713b780b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## LOADIN DATASET",
   "id": "1bcf39760a6f815a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    " print('==> Running main part of our training')\n",
    "if torch.cuda.is_available():\n",
    "    print('=> Our gpu type and uploaded driver')\n",
    "    os.system(\"nvidia-smi --query-gpu=gpu_name,driver_version --format=csv\")\n",
    "else:\n",
    "    print('==> There is no CUDA capable GPU device here!')"
   ],
   "id": "c4f381628292ea85"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "config = {\n",
    "    \"batch_size\": 2048,\n",
    "    \"epochs\": 40,\n",
    "    \"patience\": 2,\n",
    "    \"target_accuracy\": 0.85,\n",
    "    \"base_lr\": 0.01,\n",
    "}"
   ],
   "id": "77f69cb8b400b46a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    " # transform the raw data into tensors\n",
    "# Define transforms for the training and testing sets\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "train_set = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_set = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# Train only on 1/5 of the dataset\n",
    "# train_subset = torch.utils.data.Subset(train_set, list(range(0, 12000)))\n",
    "# test_subset = torch.utils.data.Subset(test_set, list(range(0, 10000)))\n",
    "train_subset = torch.utils.data.Subset(train_set, list(range(0, 10000)))\n",
    "test_subset = torch.utils.data.Subset(test_set, list(range(0, 2000)))\n",
    "\n",
    "# Training data loader\n",
    "train_loader = torch.utils.data.DataLoader(train_subset,\n",
    "                                           batch_size=config[\"batch_size\"], drop_last=True)\n",
    "# Validation data loader\n",
    "test_loader = torch.utils.data.DataLoader(test_subset,\n",
    "                                          batch_size=config[\"batch_size\"], drop_last=True)"
   ],
   "id": "2b7bfc4a917a8259"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## INIT MODEL INSTANCE",
   "id": "21c7155e41f74168"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    " # Create the model and move to GPU device if available\n",
    "num_classes = 10\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = WideResNet(num_classes).to(device)\n",
    "\n",
    "# Define loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the SGD optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=config[\"base_lr\"])\n",
    "\n",
    "val_accuracy = []\n",
    "\n",
    "# Make a change 3: initialize the variable total_time with a value of 0.\n",
    "total_time = 0"
   ],
   "id": "4f8bc5916db211cb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## TRAIN LOOP",
   "id": "93597a07fb6c1ae2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for epoch in range(config[\"epochs\"]):\n",
    "\n",
    "    # get the beginning\n",
    "    t0 = time.time()\n",
    "    os.system(\"nvidia-smi --query-gpu=temperature.gpu,utilization.gpu,utilization.memory --format=csv\")\n",
    "    train(model, optimizer, train_loader, loss_fn, device)\n",
    "\n",
    "    epoch_time = time.time() - t0\n",
    "    total_time += epoch_time\n",
    "\n",
    "    images_per_sec = len(train_loader) * config[\"batch_size\"] / epoch_time\n",
    "    v_accuracy, v_loss = test(model, test_loader, loss_fn, device)\n",
    "\n",
    "    val_accuracy.append(v_accuracy)\n",
    "\n",
    "    print(\"Epoch = {:2d}: Epoch Time = {:5.3f}, Validation Loss = {:5.3f}, Validation Accuracy = {:5.3f}, Images/sec = {}, Cumulative Time = {:5.3f}\".format(epoch+1, epoch_time, v_loss, val_accuracy[-1], images_per_sec, total_time))\n",
    "\n",
    "\n",
    "    target_accuracy_indexes = list([i for i, e in enumerate(val_accuracy) if e > config[\"target_accuracy\"]])\n",
    "    if len(target_accuracy_indexes) > 0 and target_accuracy_indexes[0] + config[\"patience\"] <= epoch:\n",
    "        print(f\"Early stopping on epoch {epoch+1}!\")\n",
    "        break"
   ],
   "id": "938e0b7e4a6211f8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
